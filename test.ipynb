{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T05:51:08.515681Z",
     "start_time": "2025-08-06T05:51:08.512735Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os.path\n",
    "import logging\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "\n",
    "from dataset.v2x_utils import Filter, RectFilter\n",
    "from dataset.base_dataset import build_path_to_info, get_annos\n",
    "from dataset.dataset_utils import load_json, InfFrame, VehFrame, VICFrame, Label"
   ],
   "id": "66609d1260c52552",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T05:51:35.888987Z",
     "start_time": "2025-08-06T05:51:35.777370Z"
    }
   },
   "cell_type": "code",
   "source": "np.random.rand(3, 2, 2).squeeze(axis=-1).shape",
   "id": "f9ec1d11ffc76a6d",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot select an axis to squeeze out which has size not equal to one",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrand\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msqueeze\u001B[49m\u001B[43m(\u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mshape\n",
      "\u001B[0;31mValueError\u001B[0m: cannot select an axis to squeeze out which has size not equal to one"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-03T14:40:07.474275Z",
     "start_time": "2025-08-03T14:40:07.463386Z"
    }
   },
   "source": [
    "class VICDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path, split=\"train\", sensortype=\"lidar\", extended_range=None, val_data_path=\"\"):\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "        self.inf_path2info = build_path_to_info(\n",
    "            \"infrastructure-side\",\n",
    "            load_json(os.path.join(path, \"infrastructure-side/data_info.json\")),\n",
    "            sensortype,\n",
    "        )\n",
    "        self.veh_path2info = build_path_to_info(\n",
    "            \"vehicle-side\",\n",
    "            load_json(os.path.join(path, \"vehicle-side/data_info.json\")),\n",
    "            sensortype,\n",
    "        )\n",
    "\n",
    "        ### Patch for FFNet evaluation ###\n",
    "        # if args.model =='feature_flow':\n",
    "        #     frame_pairs = load_json(val_data_path)\n",
    "        # else:\n",
    "        #     frame_pairs = load_json(os.path.join(path, \"cooperative/data_info.json\"))\n",
    "        #     split_path = args.split_data_path\n",
    "        #     frame_pairs = self.get_split(split_path, split, frame_pairs)\n",
    "        frame_pairs = load_json(val_data_path)\n",
    "\n",
    "        self.data = []\n",
    "        self.inf_frames = {}\n",
    "        self.veh_frames = {}\n",
    "\n",
    "        for elem in frame_pairs:\n",
    "            if sensortype == \"lidar\":\n",
    "                inf_frame = self.inf_path2info[elem[\"infrastructure_pointcloud_path\"]]\n",
    "                veh_frame = self.veh_path2info[elem[\"vehicle_pointcloud_path\"]]\n",
    "            elif sensortype == \"camera\":\n",
    "                inf_frame = self.inf_path2info[elem[\"infrastructure_image_path\"]]\n",
    "                veh_frame = self.veh_path2info[elem[\"vehicle_image_path\"]]\n",
    "                get_annos(path, \"infrastructure-side\", inf_frame, \"camera\")\n",
    "                get_annos(path, \"vehicle-side\", veh_frame, \"camera\")\n",
    "\n",
    "            inf_frame = InfFrame(path + \"/infrastructure-side/\", inf_frame)\n",
    "            veh_frame = VehFrame(path + \"/vehicle-side/\", veh_frame)\n",
    "            if not inf_frame[\"batch_id\"] in self.inf_frames:\n",
    "                self.inf_frames[inf_frame[\"batch_id\"]] = [inf_frame]\n",
    "            else:\n",
    "                self.inf_frames[inf_frame[\"batch_id\"]].append(inf_frame)\n",
    "            if not veh_frame[\"batch_id\"] in self.veh_frames:\n",
    "                self.veh_frames[veh_frame[\"batch_id\"]] = [veh_frame]\n",
    "            else:\n",
    "                self.veh_frames[veh_frame[\"batch_id\"]].append(veh_frame)\n",
    "            vic_frame = VICFrame(path, elem, veh_frame, inf_frame, 0)\n",
    "\n",
    "            # filter in world coordinate\n",
    "            if extended_range is not None:\n",
    "                trans = vic_frame.transform(from_coord=\"Vehicle_lidar\", to_coord=\"World\")\n",
    "                filt_world = RectFilter(trans(extended_range)[0])\n",
    "\n",
    "            trans_1 = vic_frame.transform(\"World\", \"Vehicle_lidar\")\n",
    "            label_v = Label(os.path.join(path, elem[\"cooperative_label_path\"]), filt_world)\n",
    "            label_v[\"boxes_3d\"] = trans_1(label_v[\"boxes_3d\"])\n",
    "            filt = RectFilter(extended_range[0])\n",
    "            tup = (\n",
    "                vic_frame,\n",
    "                label_v,\n",
    "                filt,\n",
    "            )\n",
    "            self.data.append(tup)\n",
    "\n",
    "    def query_veh_segment(self, frame, sensortype=\"lidar\", previous_only=False):\n",
    "        segment = self.veh_frames[frame.batch_id]\n",
    "        return [f for f in segment if f.id[sensortype] < frame.id[sensortype] or not previous_only]\n",
    "\n",
    "    def query_inf_segment(self, frame, sensortype=\"lidar\", previous_only=False):\n",
    "        segment = self.inf_frames[frame.batch_id]\n",
    "        return [f for f in segment if f.id[sensortype] < frame.id[sensortype] or not previous_only]\n",
    "\n",
    "    def get_split(self, split_path, split, frame_pairs):\n",
    "        if os.path.exists(split_path):\n",
    "            split_data = load_json(split_path)\n",
    "        else:\n",
    "            print(\"Split File Doesn't Exists!\")\n",
    "            raise Exception\n",
    "\n",
    "        if split in [\"train\", \"val\", \"test\"]:\n",
    "            split_data = split_data[\"cooperative_split\"][split]\n",
    "        else:\n",
    "            print(\"Split Method Doesn't Exists!\")\n",
    "            raise Exception\n",
    "\n",
    "        frame_pairs_split = []\n",
    "        for frame_pair in frame_pairs:\n",
    "            veh_frame_idx = frame_pair[\"vehicle_image_path\"].split(\"/\")[-1].replace(\".jpg\", \"\")\n",
    "            if veh_frame_idx in split_data:\n",
    "                frame_pairs_split.append(frame_pair)\n",
    "        return frame_pairs_split\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class VICSyncDataset(VICDataset):\n",
    "    def __init__(self, path, split=\"train\", sensortype=\"lidar\", extended_range=None, val_data_path=\"\"):\n",
    "        super().__init__(path, split, sensortype, extended_range, val_data_path)\n",
    "        logging.info(\"VIC-Sync {} dataset, overall {} frames\".format(split, len(self.data)))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T14:42:27.128926Z",
     "start_time": "2025-08-03T14:42:26.893156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "VICSyncDataset(\n",
    "    path='/Volumes/BetaCat-USB/DAIR-V2X-C/cooperative-vehicle-infrastructure',\n",
    "    split='train',\n",
    "    sensortype='camera',\n",
    ")"
   ],
   "id": "3a3936a36f1ca2dd",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: ''",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mVICSyncDataset\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m/Volumes/BetaCat-USB/DAIR-V2X-C/cooperative-vehicle-infrastructure\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43msplit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtrain\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43msensortype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcamera\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[6], line 101\u001B[0m, in \u001B[0;36mVICSyncDataset.__init__\u001B[0;34m(self, path, split, sensortype, extended_range, val_data_path)\u001B[0m\n\u001B[1;32m    100\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, path, split\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m, sensortype\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlidar\u001B[39m\u001B[38;5;124m\"\u001B[39m, extended_range\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, val_data_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 101\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msplit\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msensortype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextended_range\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_data_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    102\u001B[0m     logging\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mVIC-Sync \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m dataset, overall \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m frames\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(split, \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata)))\n",
      "Cell \u001B[0;32mIn[6], line 23\u001B[0m, in \u001B[0;36mVICDataset.__init__\u001B[0;34m(self, path, split, sensortype, extended_range, val_data_path)\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mveh_path2info \u001B[38;5;241m=\u001B[39m build_path_to_info(\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvehicle-side\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     12\u001B[0m     load_json(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvehicle-side/data_info.json\u001B[39m\u001B[38;5;124m\"\u001B[39m)),\n\u001B[1;32m     13\u001B[0m     sensortype,\n\u001B[1;32m     14\u001B[0m )\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m### Patch for FFNet evaluation ###\u001B[39;00m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m# if args.model =='feature_flow':\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m#     frame_pairs = load_json(val_data_path)\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m#     split_path = args.split_data_path\u001B[39;00m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m#     frame_pairs = self.get_split(split_path, split, frame_pairs)\u001B[39;00m\n\u001B[0;32m---> 23\u001B[0m frame_pairs \u001B[38;5;241m=\u001B[39m \u001B[43mload_json\u001B[49m\u001B[43m(\u001B[49m\u001B[43mval_data_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minf_frames \u001B[38;5;241m=\u001B[39m {}\n",
      "File \u001B[0;32m~/Downloads/DAIR_dataloader/dataset/dataset_utils/file_io.py:11\u001B[0m, in \u001B[0;36mload_json\u001B[0;34m(path)\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mload_json\u001B[39m(path):\n\u001B[0;32m---> 11\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m     12\u001B[0m         data \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mload(f)\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: ''"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
